---
version: '3.2'

services:
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - 2181:2181

  kafka:
    image: wurstmeister/kafka:latest
    container_name: kafka
    hostname: kafka
    ports:
      - target: 9094
        published: 9094
        protocol: tcp
        mode: host
    environment:
      HOSTNAME_COMMAND: "docker info | grep ^Name: | cut -d' ' -f 2"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INSIDE://:9092,OUTSIDE://_{HOSTNAME_COMMAND}:9094
      KAFKA_LISTENERS: INSIDE://:9092,OUTSIDE://:9094
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  mongo:
    image: mongo:4.4.13
    container_name: mongo
    hostname: mongo
    restart: always
    ports:
      - 27017:27017
    networks:
     - swarm_network
    # Mounting volume to save data on host machine
    volumes:
     - ../mongodb/data:/data/db
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongo mongo:27017/test --quiet
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s

  mongo-express:
    image: mongo-express
    container_name: mongo_express
    hostname: mongo_express
    restart: always
    depends_on:
     mongo:
       condition: service_healthy
    ports:
      - 8081:8081
    networks:
     - swarm_network
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      ME_CONFIG_MONGODB_ADMINPASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
      ME_CONFIG_MONGODB_URL: mongodb://${MONGO_INITDB_ROOT_USERNAME}:${MONGO_INITDB_ROOT_PASSWORD}@mongo:27017/

  rss_scraper:
    image: ghcr.io/oth-datapipeline/scraping-scripts:develop
    hostname: rss_scraper
    container_name: rss_scraper
    networks:
    - docker_kafka
    depends_on:
      kafka:
        condition: service_healthy
      mongo:
        condition: service_healthy
    environment:
      REDDIT_CLIENT_ID: ${REDDIT_CLIENT_ID}
      REDDIT_CLIENT_SECRET: ${REDDIT_CLIENT_SECRET}
      TWITTER_CONSUMER_KEY: ${TWITTER_CONSUMER_KEY}
      TWITTER_CONSUMER_SECRET: ${TWITTER_CONSUMER_SECRET}
      TWITTER_BEARER_TOKEN: ${TWITTER_BEARER_TOKEN}
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
    entrypoint:
    - bash
    - -c
    - |
      echo 'Executing scraper for rss...'
      python3 src/data_collection.py --config=config.json "rss" --base_url=https://blog.feedspot.com/world_news_rss_feeds/

networks:
  swarm_network:
    external: true